import streamlit as st
from langchain_ollama import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate
import ast
from app import user_inputs


st.title("ğŸ‘‰ğŸ»KarÅŸÄ±lÄ±klÄ± MÃ¼lakatğŸ‘ˆğŸ»")


# Model ve prompt'u tanÄ±mla
model = OllamaLLM(model="llama3")

# MÃ¼lakat baÄŸlamÄ±nÄ± baÅŸlat
if "interview_context" not in st.session_state:
    st.session_state.interview_context = []

# KullanÄ±cÄ± inputunu temizlemek iÃ§in bir durum belirleyelim
if "input_key" not in st.session_state:
    st.session_state.input_key = "user_input_0"

# Ä°lk soru, AI tarafÄ±ndan sorulur
if not st.session_state.interview_context:
    initial_question = (
        f"Welcome! You have applied for a {user_inputs[0]} position at a {user_inputs[1]} difficulty level. "
        "Are you ready to start the interview?"
    )
    st.session_state.interview_context.append({"question": initial_question, "answer": None})

# KonuÅŸma geÃ§miÅŸini gÃ¶rÃ¼ntÃ¼le
st.markdown("<div style='background-color:#1a1a2e; padding:10px; border-radius:10px; max-height:300px; overflow-y:scroll;'>", unsafe_allow_html=True)

for entry in st.session_state.interview_context:
    question = entry['question']
    # EÄŸer soru dict veya baÅŸka bir yapÄ±daysa, stringe Ã§evir ve gÃ¶ster
    if isinstance(question, dict):
        question = str(question)

    st.markdown(f"<p style='color:#f8f8ff; background-color:#16213e; padding:10px; border-radius:10px; margin-bottom:5px; max-width:70%; align-self:flex-start;'><strong>AI: {question}</strong></p>", unsafe_allow_html=True)
    if entry['answer']:
        st.markdown(f"<p style='color:#f8f8ff; background-color:#0f3460; padding:10px; border-radius:10px; margin-bottom:5px; max-width:70%; align-self:flex-end;'><strong>User: {entry['answer']}</strong></p>", unsafe_allow_html=True)

st.markdown("</div>", unsafe_allow_html=True)

# KullanÄ±cÄ±dan input al
user_input = st.text_input("Your answer:", key=st.session_state.input_key)

# EÄŸer kullanÄ±cÄ± bir input girdiyse ve 'GÃ¶nder' butonuna basarsa
if st.button("GÃ¶nder"):
    if user_input:
        # KullanÄ±cÄ±nÄ±n cevabÄ±nÄ± baÄŸlama ekle
        st.session_state.interview_context[-1]["answer"] = user_input

        # CevabÄ±n doÄŸru olup olmadÄ±ÄŸÄ±nÄ± deÄŸerlendir
        evaluation_prompt = (
            f"The candidate provided the following answer: '{user_input}' for the question '{st.session_state.interview_context[-1]['question']}'. "
            "Please evaluate if this answer is correct or incorrect, and explain briefly."
        )

        evaluation_result = model.invoke(input=evaluation_prompt)
        st.session_state.interview_context.append({"question": "Evaluation", "answer": evaluation_result})

        # Ã–nceki baÄŸlama gÃ¶re yeni mÃ¼lakat sorusu oluÅŸtur
        question_prompt = (
            f"The candidate has applied for the {user_inputs[0]} position at a {user_inputs[1]} difficulty level. "
            f"Here is the context so far: {st.session_state.interview_context}. Please provide the next interview question without extra commentary."
        )

        # Modeli Ã§alÄ±ÅŸtÄ±rarak mÃ¼lakat sorusunu al
        question_result = model.invoke(input=question_prompt)

        # EÄŸer result bir dict veya baÅŸka bir yapÄ±daysa, stringe Ã§evir
        try:
            question_result = ast.literal_eval(question_result)
        except:
            pass

        # Yeni soruyu baÄŸlama ekle
        st.session_state.interview_context.append({"question": question_result, "answer": None})

        # Cevap kutusunu temizlemek iÃ§in input key'ini deÄŸiÅŸtir
        st.session_state.input_key = f"user_input_{len(st.session_state.interview_context)}"
        #st.experimental_rerun()



# #ana sayfaya dÃ¶n
# def open_main():                   
#     url = 'http://localhost:8501'  
#     webbrowser.open_new_tab(url)

# st.button("Ana Sayfaya DÃ¶n", on_click=open_main)